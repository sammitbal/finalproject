---
title: "FinalProject"
author: "Sammit Bal, Jason Zheng, Thaddeus Poff"
date: "2025-04-27"
output: html_document
---

```{=html}
<style>
blockquote {
font-size: 1em;
}
</style>
```

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Frontmatter

```{r}
remove(list = ls())
library(glmnet)
library(rpart)
library(rattle) # for the fancyRpartPlot()
library(tidyverse)
library(readxl)
library(stringr)
library(e1071)
library(caret)

CODMaps <- read.csv("./CODMaps.csv")
CODGames_p2_380 <- read.csv("./CODGames_p2_380.csv")
CODGames_p1_380 <- read.csv("./CODGames_p1_380.csv")
CODGameModes <- read.csv("./CODGameModes.csv")

#combined cod dataset
COD_combined <- bind_rows(CODGames_p1_380, CODGames_p2_380)

```

## Task 1: Data Cleaning and Data Visualization

> *Relevant Information:* (Complete without using Generative AI) Prior to each online match, players in the game lobby are presented with two options for the battlefield of the upcoming game (`Map1` and `Map2`). The players have the option to vote and the resulting vote is recorded in the `MapVote` column. The winning map is listed in the `Choice` column. In the event of a tie vote, the map listed in `Map1` is chosen. (Games for which the player entered the lobby after the vote has taken place have no information in `Map1` and `Map2` but have the winning map presented in `Choice`.)

**Research Question:** Which maps are the most likely to win the map vote when they are an option?

*Notes:* To answer this question... 

1.  Write a paragraph (or more) discussing how you plan to answer this question (Be sure to address the data quality issues mentioned below and discuss how you will do the calculations).
2.  Then, write code and answer the question. (If I must answer questions about your approach/decision making process by reading your code rather than your discussion, you will lose points.)
3.  As part of your solution, you should calculate the proportion/probability that a map wins the vote given that it was a candidate.

*Note:* To do this, you will have to calculate the number times that each map was listed as a candidate (Map1 or Map2) and earned more votes than the other candidate.

-   As part of this, you should consider whether a given map won the vote by getting more votes than the other option or if it was selected since it was `Map1` and the vote was a tie.
-   You should also include a visualization of the results.
-   There might be some data quality issues (such as misspelled map names and extra (trailing) blanks in some entries) to solve for this problem.
-   You can find the proper names/spellings in the CODMaps.csv file.
-   **Warning:** To full receive full credit, you must write code to solve these issues rather than editing the `.csv` files



**Discussion:**



I plan to answer the research question by first addressing the data quality issues and the misspellings. I will do this by creating a word bank of all the misspellings and then run the data through the word bank to make sure every map is spelled correctly. Also to get rid of the blank spaces I will just not include rows with a blank in place. Then to do the calculations I will start by counting how many times each map was candidate by looking at the Map1 and Map2 columns. Then I will count the amount of times the map was selected, call these "wins". Finally I will divide the wins by the appearances to get a win rate. This win rate will than be plotted to show us which maps had the highest and lowest win rates. 




```{r}
COD_combined <- 
  COD_combined[COD_combined$Map1 != "", ]

Map_select <- COD_combined %>%
  select(Map1, Map2, Choice)

Map_select$Map1_clean <- tolower(Map_select$Map1)

Map_select$Map2_clean <- tolower(Map_select$Map2)

Map_select$Choice_clean <- tolower(Map_select$Choice)

#found 6 misspellings 
corrections <- c(
  "aPocalypse" = "Apocalypse",
  "apocolypse" = "Apocalypse",
  "Apocolypse" = "Apocalypse",
  "collaterel strike" = "Collateral Strike",
  "apocalypse" = "Apocalypse",
  "deisel" = "Diesel",
  "drive-in" = "Drive-In", 
  "yamantau" = "Yamantau", 
  "miami stirke" = "Miami Strike",
  "riad" = "Raid",
  "ruah" = "Raid",
  "raid " = "Raid",
  "amrada strike" = "Armada Strike",
  "deprogam" = "Deprogram",
  "miami Sstrike" = "Miami Strike",
  "miami Stirke" = "Miami Strike",
  "rush " = "Rush",
  "zoo " = "Zoo",
  "miami sstrike" = "Miami Strike",
  "collateral striek" = "Collateral Strike",
  "collaterol strike" = "Collateral Strike",
  "jungle " = "Jungle",
  "miami " = "Miami"
)

#comparing choices to misspelled words then correcting them if misspelled.
Map_select$Map1_clean <- ifelse(
  Map_select$Map1_clean %in% names(corrections),
  corrections[Map_select$Map1_clean],
  Map_select$Map1  
)

Map_select$Map2_clean <- ifelse(
  Map_select$Map2_clean %in% names(corrections),
  corrections[Map_select$Map2_clean],
  Map_select$Map2  
)

Map_select$Choice_clean <- ifelse(
  Map_select$Choice_clean %in% names(corrections),
  corrections[Map_select$Choice_clean],
  Map_select$Choice  
)

```


```{r}
# Count appearances
appearances <- Map_select %>%
  select(Map1_clean, Map2_clean) %>%
  pivot_longer(cols = everything(), values_to = "Map") %>%
  count(Map, name = "appearances")

# Count wins
wins <- Map_select %>%
  filter(Choice_clean == Map1_clean | Choice_clean == Map2_clean) %>%
  count(Choice_clean, name = "wins") %>%
  rename(Map = Choice_clean)

#calculate win rate
Map_stats <- appearances %>%
  left_join(wins, by = "Map") %>%
  mutate(win_rate = wins / appearances) %>%
  arrange(desc(win_rate))

```


```{r}
ggplot(Map_stats, aes(x = reorder(Map, win_rate), y = win_rate)) +
  geom_col() +
  geom_text(aes(label = paste0("n=", wins)), 
            hjust = -0.1, 
            size = 3.75) +
  coord_flip() +
  labs(
    title = "Map Win Rate",
    x = "Map",
    y = "Win Rate (n = Number of Times Map Won When Offered)"
  ) +
  theme_minimal()

```




**Discussion:**



Looking at the plot we can see Win Rate on the x-axis and Map on the y-axis. We can also see next to each bar how many times the map won when offered to the players. The top three win rates are for Nuketown 84', Crossroads Strike, and Raid. I left out Nuketown Halloween because it was only offered and chosen once and it is technically a repeat of Nuketown 84'. So to answer the question Nuketown 84', Crossroads Strike, and Raid are the maps most likely to win the map vote when they are an option.





## Task 2: Data Cleaning and Data Visualization

**Question:** Repeat Task 1 using a generative AI of your choice.

1.  To answer this question, mention the tool (including version number if appropriate) you have selected.
2.  Then, discuss the prompt(s) you have used and provide the solution produced by the generative AI.

> *Note:* While it is fine to paste the question into the generative AI as your first prompt, you should also use additional follow-up prompts if it is beneficial to do so. - Be sure to discuss all prompts used in your report.

3.  Then, implement the generative AI solution.
4.  Finally, and most importantly, you should compare your solution from Task 1 to the generative AI solution.

> *Note 2:*
>
> -   Discuss similarities/differences, strengths/weaknesses, etc., and provide an overall assessment of which solution is better.
> -   The discussion should consider the correctness of the answers and should be substantial.
> -   Demonstrate that you have given the comparison considerable thought by making at least 3 substantial points as part of your comparison. - Each point should take the form of a well-written paragraph.


To answer the question "Which maps are the most likely to win the map vote when they are an option?" using generative AI we broke the question into a few parts. The first part dealt with the data quality issues. 



To deal with the misspelled words in the dataset I asked ChatGPT:"i need to remove misspelled rows from the dataset."




This was the code provided. 
```{r}
valid_maps <- c("Deprogram", "Collateral Strike", "Collateral", "Amerika", "Crossroads Strike", "Raid", "Rush", "Satellite", "Miami", "Cartel", "Hijacked", "Miami Strike", "Yamantau", "Drive-In", "WMD", "Standoff", "Garrison", "Nuketown '84", "Express", "Zoo", "Armada Strike", "Diesel", "Slums", "Echelon", "Apocalypse", "Checkmate", "Moscow", "The Pines", "Jungle")  # add all correct map names
# filter(MapCandidate %in% valid_maps) (additional code from same prompt to remove misspelled maps)
```



Then using chatGPT I asked: "Prior to each online match, players in the game lobby are presented with two options for the battlefield of the upcoming game (Map1 and Map2). The players have the option to vote and the resulting vote is recorded in the MapVote column. The winning map is listed in the Choice column. In the event of a tie vote, the map listed in Map1 is chosen. (Games for which the player entered the lobby after the vote has taken place have no information in Map1 and Map2 but have the winning map presented in Choice.)Which maps are the most likely to win the map vote when they are an option?As part of your solution, you should calculate the proportion/probability that a map wins the vote given that it was a candidate.

*Note:* To do this, you will have to calculate the number times that each map was listed as a candidate (Map1 or Map2) and earned more votes than the other candidate.

-   As part of this, you should consider whether a given map won the vote by getting more votes than the other option or if it was selected since it was Map1 and the vote was a tie.
-   You should also include a visualization of the results.
-   There might be some data quality issues (such as misspelled map names and extra (trailing) blanks in some entries) to solve for this problem." Which gave me this code and visualization. ". 


Here is the code provided:


```{r, eval=FALSE}

# Step 1: Clean up map names (remove trailing/leading spaces, convert to lowercase if needed)
data_clean <- COD_combined %>%
  mutate(across(c(Map1, Map2, Choice), ~str_trim(.)))




data_clean <- data_clean %>%
  mutate(
    is_draw = str_detect(MapVote, "^\\s*\\d+\\s*to\\s*\\d+\\s*$") &
      as.numeric(str_extract(MapVote, "^\\s*\\d+")) == as.numeric(str_extract(MapVote, "\\d+\\s*$"))
  )

# Step 2: Create a column for which map actually won by vote (excluding ties)
vote_results <- data_clean %>%
  filter(!is.na(Map1) & !is.na(Map2) & !is.na(MapVote)) %>%
  mutate(
    vote_winner = case_when(
      is_draw ~ Map1,
      TRUE ~ Choice
    )
  )


# Step 3: Reshape into long format to count wins and appearances
long_data <- vote_results %>%
  pivot_longer(cols = c(Map1, Map2), names_to = "MapSlot", values_to = "MapCandidate") %>%
  mutate(win = MapCandidate == vote_winner) %>%
  filter(MapCandidate %in% valid_maps)


# Step 4: Count how many times each map was offered and how many times it won
map_stats <- long_data %>%
  group_by(MapCandidate) %>%
  summarise(
    times_offered = n(),
    times_won = sum(win),
    win_rate = times_won / times_offered
  ) %>%
  arrange(desc(win_rate))



draws_per_map <- vote_results %>%
  filter(is_draw) %>%
  pivot_longer(cols = c(Map1, Map2), names_to = "MapSlot", values_to = "MapCandidate") %>%
  group_by(MapCandidate) %>%
  summarise(draws = n(), .groups = "drop")



map_stats <- map_stats %>%
  left_join(draws_per_map, by = "MapCandidate") %>%
  mutate(draws = replace_na(draws, 0))  # Fill NA with 0 for maps with no draws



print(map_stats)

```




```{r, eval=FALSE}
ggplot(map_stats, aes(x = reorder(MapCandidate, win_rate), y = win_rate)) +
  geom_col(fill = "steelblue") +
  coord_flip() +
  labs(
    title = "Map Win Rate When Offered",
    x = "Map",
    y = "Win Rate"
  ) +
  theme_minimal()

```










When comparing both soliutions, there are a few noticeable differences. The first one being the table and visualization of the solution from ChatGPT is easier to read and understand. The table clearly states the map name, how many times it was a candidate, and how many times it was selected. Along with providing the winning rate that the map was chosen. It also implemented a coluimn for the amount of draws each map had. Our solution did not include a table that clearly showed the proportions to each map. Instead the visualization sort of combined it. With each map, there is the number of times it was selected, along with the win rate. Although, the win rate is not given as a specific percentage like in the ChatGPT solution. The visualization from the ChatGPT solution is much more effective and easier to interpret, the table gives a clear representation of how many times each map was selected and their win rate. With that being said, I believe ChatGPT provided a more comprehensive answer that was easy to understand and aesthetically pleasing. 


When it came to asking and getting ChatGPT to give me the answers I was looking for, I had to be very clear and precise in what I was asking, or it would not give me the correct answer. For exmaple, when I was asking ChatGPT how to add a column for total ties it was giving me code where ties were equal to 0. This is obviously not the case if you look at the MapVote column. So I told ChatGPT exactly how it was, "A tie is 3 to 3" and that's when it gave me the answer I was desiring. That was the only hiccup I dealt with when trying to get ChatGPT to answer the research question. This was my exact question to ChatGPT:"a draw from this dataset would be something like '3 to 3'. 

And the response ChatGPT gave me was the following: 

'Thanks — that changes everything. If draws are recorded as strings like "3 to 3" in the MapVote column, then your current logic using MapVote == 0 will never detect ties.'



Overall, ChatGPT had some few difficulties answering the research question, but as previously stated, that is because I was not being specific enough. Once I started being specific in what I was looking for, it gave me what I was looking for. I believe it did a good job at answering the question. Obviously it isn't perfect, I don't think anyone expects that.



## Task 3: Inference

*Relevant Information:* There are a variety games types (GameType variable) within this dataset.

-   The difference between the game types is that players have different objectives for the game.
-   For instance, in the game type “Hardpoint”, teams earn points by capturing and defending a location. - In “TDM” teams earn points by eliminating enemy opponents. As these game types have different objectives and may last for different amounts of time, the game type might affect the TotalXP earned.

**Research Question:** How does the game type affect TotalXP after accounting for the Score?

*Notes:* Score refers to the player’s score, not the “score” of the match (i.e., not the Result column).

-   This answer requires some data wrangling that may require knowledge that we have not covered. (Again, part of the skillset you are working to develop is learning how to answer questions you have not seen previously.)
-   In particular, there is no distinction between HC – TDM and TDM, no difference between HC – Hardpoint and Hardpoint, and so on for the other game types.

**Process of Answering:**

1.  Write code to clean the values in the GameType column to reflect this information.
2.  Then, perform an exploratory data analysis by create appropriate visualizations/summary statistics that explore the distribution of the variables and show the relationship between TotalXP, Score, and GameType. (You decide on the type/number of visualizations, but the analysis should be complete.)
3.  Finally, build an appropriate model for TotalXP based on Score and GameType. You should use the model to then answer the research question.


```{r}
COD_combined <- bind_rows(CODGames_p1_380, CODGames_p2_380)

#Step 1 
df_cleaned <- COD_combined %>%
  mutate(GameType = str_replace(GameType, "^HC.*?(?=\\w)", ""))
```


```{r}
# Summary statistics of Score and TotalXP by GameType
df <- df_cleaned %>%
  group_by(GameType) %>%
  summarize(
    count = n(),
    mean_score = mean(Score, na.rm = TRUE),
    mean_totalxp = mean(TotalXP, na.rm = TRUE),
    sd_totalxp = sd(TotalXP, na.rm = TRUE),
    correlation = cor(Score, TotalXP, use = "complete.obs")
  )


df
```


```{r}
#scatterplot with trend lines
ggplot(df_cleaned, aes(x = Score, y = TotalXP, color = GameType)) +
  geom_point(alpha = 0.5) +
  geom_smooth(method = "lm", se = FALSE) +
  theme_minimal() +
  labs(title = "Score vs. TotalXP by GameType", x = "Score", y = "TotalXP")

#boxplot 
ggplot(df_cleaned, aes(x = GameType, y = TotalXP)) +
  geom_boxplot() +
  theme_minimal() +
  labs(title = "Distribution of TotalXP by GameType", x = "GameType", y = "TotalXP")

#histogram
ggplot(df, aes(x = GameType, y = mean_score)) +
  geom_boxplot(width = 5)+
  geom_col() +
  labs(title = "Distribution of Score by GameType", x = "GameType", y = "TotalXP") +
  theme_minimal()

```



**Analysis:** 



Looking at first scatterplot we can observe a pretty obvious positive correlation between Score and TotalXP. This correlation is shared by all the GameTypes. Looking closer at the best fit lines we can see which GameType has the better correlation. To get a more exact correlation value take a look at the summary statistics which will tell you that Domination has the best correlation between Score and TotalXP at 0.72. The best to worst correlation order goes from Domination, Kill Confirmed, Hardpoint, to TDM. Looking at the box plot tells us that Kill Confirmed on average has a lower TotalXP compared to the other game types. When we switch to the Mean Score plot we see more of the same, Kill Confirmed is the only game type with a mean score of less than 3000.  




```{r}

#How does the game type affect TotalXP after accounting for the Score?

model <- lm(TotalXP ~ GameType + Score, data = df_cleaned)
summary(model)

```




**Discussion:** 



After accounting for the Score, the multiple linear regression model indicates varying effects of game type on TotalXP relative to Domination. Playing Hardpoint shows a positive trend, with an estimated increase of 121.76 TotalXP compared to Domination. Conversely, playing Kill Confirmed suggests a  significant negative impact, with an estimated decrease of about 3703.17 TotalXP compared to Domination. Similarly, playing TDM indicates a negative trend, with roughly 2570.44 less TotalXP compared to Domination. This indicates that while Score is a strong predictor of TotalXP, different game types can affect TotalXP differently. Examining for statistical significance tells us that Hardpoint and TDM are not statistically significant at the 0.05 level. Kill Confirmed with a p = 0.0632 (not < 0.05 but closest to it), however, shows some evidence of leading to lower TotalXP after considering a player's Score. This is backed up by our earlier plots and summary statistics. Overall, GameType affects TotalXP in many different ways, Kill Confirmed leading to a generally lower TotalXP is just the most significant example we have.  




## Task 4: Prediction

> Relevant Information: In this task, your goal is to compare a variety of classification methods. In particular, you should write your own research question that can be answered by comparing the effectiveness of various classification methodologies. To demonstrate your understanding of these methods, you should implement two classification methods from class, one of which must be random forest, and a third method that we will not cover in class. (The purpose of the using a method we did not cover is I want you to practice learning about a method and its implementation on your own. Basically, find a tutorial that explains the method and how to implement it.) You will then have to compare the results and decide which method was the most effective.

**Research Question:** Write your own question and be sure that the question and answer are clearly written in your report.

*Notes:* Since you will be using random forest, do not use a decision/classification tree as one of your other methods.

-   For this problem, you should provide a brief description of the methods that you will use. (A description is more than listing the name of the procedure. You should describe how the procedure works.)
-   You will implement and compare the effectiveness of these methods. As part of this process, you will have to make a number of decisions such as whether you will do any data wrangling.
-   *EX:* Maybe you remove partial matches, maybe you create new variables, etc.), which methods will you use, how will you fairly compare the results between methods, which method is best etc. **All of these decisions should be included in your report.**
-   **Warning:** If I have to learn about your decisions/analysis by reading your code, you will lose points.

*NOTE1:* You will make your life easier if you pick a response with a small number of levels.

*NOTE2:* As you are picking a method that we did not cover, one way to find techniques is by looking at the textbook that we have been covering: An Introduction to Statistical Learning with Applications in R by Gareth James et al. You can find a pdf of the textbook on the author’s site: <https://www.statlearning.com/>.


#### Deciding the Research Question

**Question:** Decide which game mode was played based off of the Eliminations, Score, Damage, and Total XP.

```{r}
# DF to predict game mode
COD_gm <- COD_combined %>%
  filter(!is.na(Eliminations) & !is.na(Score) &
         !is.na(Damage) & !is.na(TotalXP)) %>%
  select(c(GameType, Eliminations, Score, Damage, TotalXP))

nrow(COD_gm) ## How many rows? Enough to do data analysis?

# Viewing the dataset
set.seed(380)
COD_gm[sample(nrow(COD_gm), 5), ]
set.seed(NULL)

# Fixing the formatting for GameType
COD_gm <- COD_gm %>%
  mutate(GameType = ifelse(grepl("Domination", GameType), "Domination",
                    ifelse(grepl("Kill Confirmed", GameType), "Kill Confirmed",
                    ifelse(grepl("Hardpoint", GameType), "Hardpoint",
                    ifelse(grepl("TDM", GameType), "TDM", "Other")))))

sum(COD_gm$GameType == "Other") # Checking for errors
```

The research question was decided based off of a filtered and combined dataset, "COD Game Mode", or `COD_gm` in the code. Data wrangling included checking the number of `NA`s in the dataset (to filter them out upon detection), and checking the remaining amount of match data (253), which is more than sufficient for predicting the four possible response levels for `CODGameModes` ("Domination", "Kill Confirmed", "Hardpoint", or "TDM"). 

One important correction in the process is rectifying the difference in notation for `GameMode`--- Player1 seems to have "`HC - `" appended to their game modes, which should be converted to the equivalent mode in `CODGameModes`. While there is a difference in the notation, which likely corresponds to a difference in the games themselves, the goal of this activity is to aggregate the statistics across the game mode itself, which includes both variations. 


#### Processing the Data & Comparison

```{r}
## Training/Validaiton Split
set.seed(380)
trainInd <- sample(1:nrow(COD_gm), 
				    floor(0.6 * nrow(COD_gm)))
set.seed(NULL)

Train <- COD_gm[trainInd, ]
Validation <- COD_gm[-trainInd, ]

## Examining the levels of data split
table(Train$GameType)
table(Validation$GameType)
```

**Processing the Data:**
To perform a proper comparison between the two Classification Methods--- Random Forest (the specified method) and through a Support Vector Machine--- it's necessary to perform a Training/Validation split. What this split means is that, for example, if you have a set of data points that you give your machine, it might MEMORIZE the data points, and therefore be really good (the best among the models) at predicting that data, but when it comes time to predict REAL-WORLD DATA that it's not seen before, its predictions might fall way off the mark. The Training/Validation split is useful for both Classification Methods because it approximates "real-world" data by sub-setting a percentage of data that it will use as a simulation of "real-world data", hides it from the model, and only uses the data for testing it in a "real-world situation". 

The utility of this in our case is because we want an answer that applies not to just these two `Player 1` and `Player 2` datasets but to players in general. The Training/Validation split emulates this for both models, and therefore will help get a closer-to-"true" model comparison, so that we can fairly select the "real best model" for answering the question.

**Examining the Levels:** 
One of the greater concerns regarding this 60/40 Training/Validation split is the lack of data on `Domination` or `Kill Confirmed`, as both players played a disproportionate amount of the other two modes and not that much of either of the three. Therefore, our accuracy figures across both models may not predict `Domination` or `Kill Confirmed` data that accurately. 

Nonetheless, the ability of both models to predict which of the four modes is being played is still possible to answer with the data, albeit with that uncertaincy meaning the results might have greater variance. 


#### Random Forest

```{r}
set.seed(123)
rfModel <- randomForest(as.factor(GameType) ~ .,
          					    data = Train,
          					    ntree = 500,
          					    mtry = 3) # 3 vars wrt next split
set.seed(NULL)
```

```{r}
# R selects threshold
predGameType <- predict(rfModel,
                        newdata = Validation, 
                        type = "response")

# Create the confusion matrix
confusionMatrix(predGameType, as.factor(Validation$GameType))
```
